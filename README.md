# üè• Healthcare Chatbot - NLP Project

An intelligent healthcare chatbot using **BiLSTM + Attention mechanism** for intent classification and symptom detection. Built with PyTorch, this chatbot can understand natural language queries about common health symptoms and provide appropriate responses.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## üìä **Performance Metrics**

- **Test Accuracy**: 94.57%
- **F1 Score (Weighted)**: 94.48%
- **F1 Score (Macro)**: 94.17%
- **Model Size**: 16.3M parameters
- **Training Time**: ~15 minutes (CPU)
- **Inference Speed**: <100ms per query

---

## ‚ú® **Key Features**

- üß† **Advanced Architecture**: BiLSTM with Attention mechanism
- üéØ **High Accuracy**: 94%+ accuracy on test set
- üí¨ **Natural Language**: Understands variations like "I have a fever", "I got fever", "my temperature is high"
- üîç **12 Intent Categories**: Greetings, farewells, thanks, and 8 health symptoms
- üìà **Word2Vec Embeddings**: 256-dimensional pre-trained embeddings
- üé® **Interactive CLI**: Real-time chat interface with confidence scores
- üìä **Comprehensive Metrics**: Confusion matrices, training history, per-class performance

---

## üèóÔ∏è **Architecture**

```
User Input: "I have a fever"
        ‚Üì
[Tokenization & Stemming]
        ‚Üì
[Word2Vec Embeddings] (256-dim)
        ‚Üì
[BiLSTM] (3 layers, 512 hidden units, bidirectional)
        ‚Üì
[Attention Layer] (focuses on important words)
        ‚Üì
[Fully Connected Layers]
        ‚Üì
[Softmax] ‚Üí Intent Classification
        ‚Üì
Output: "fever" (100% confidence)
```

### **Model Components:**
- **Embedding Layer**: 256-dimensional Word2Vec embeddings
- **BiLSTM**: 3 layers with 512 hidden units (bidirectional)
- **Attention Mechanism**: Weighted sum of LSTM outputs
- **Dropout**: 0.7 for regularization
- **Output**: 12 intent classes

---

## üìÅ **Project Structure**

```
healthcare-chatbot/
‚îú‚îÄ‚îÄ README.md                   # Project documentation
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ .gitignore                 # Git ignore rules
‚îú‚îÄ‚îÄ train.py                   # Model training script
‚îú‚îÄ‚îÄ chatbot.py                 # Interactive chatbot interface
‚îú‚îÄ‚îÄ run.py                     # Unified entry point
‚îÇ
‚îú‚îÄ‚îÄ api/                       # API module (future implementation)
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py              # Configuration settings
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ intents_working.json   # Training data (854 patterns)
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ neural_net.py          # BiLSTM + Attention model
‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py      # Data preprocessing pipeline
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py          # Word2Vec training
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ nltk_utils.py          # Text preprocessing utilities
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py          # Model evaluation & metrics
‚îÇ   ‚îî‚îÄ‚îÄ logger.py              # Logging utilities
‚îÇ
‚îî‚îÄ‚îÄ outputs/
    ‚îú‚îÄ‚îÄ models/
    ‚îÇ   ‚îú‚îÄ‚îÄ best_model.pth           # Trained model (94.57% accuracy)
    ‚îÇ   ‚îú‚îÄ‚îÄ training_data.pkl        # Preprocessed data
    ‚îÇ   ‚îî‚îÄ‚îÄ embeddings.pkl           # Word2Vec embeddings
    ‚îú‚îÄ‚îÄ logs/                        # Training logs
    ‚îî‚îÄ‚îÄ metrics/
        ‚îú‚îÄ‚îÄ confusion_matrix.png            # Confusion matrix
        ‚îú‚îÄ‚îÄ training_history.png            # Training curves
        ‚îú‚îÄ‚îÄ per_class_metrics.png           # Per-intent metrics
        ‚îî‚îÄ‚îÄ classification_report.txt       # Detailed metrics
```

---

## üöÄ **Quick Start**

### **Prerequisites**
- Python 3.8 or higher
- pip (Python package manager)
- 2GB RAM minimum
- ~500MB disk space

### **Installation**

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/healthcare-chatbot.git
   cd healthcare-chatbot
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   
   # Activate (Linux/Mac)
   source venv/bin/activate
   
   # Activate (Windows)
   venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

4. **Download NLTK data**
   ```bash
   python -c "import nltk; nltk.download('punkt'); nltk.download('wordnet'); nltk.download('stopwords'); nltk.download('punkt_tab'); nltk.download('omw-1.4')"
   ```

---

## üíª **Usage**

### **Option 1: Using run.py (Recommended)**

```bash
# Train the model
python run.py train

# Run interactive chatbot
python run.py chat

# Quick test
python run.py test
```

### **Option 2: Direct Scripts**

```bash
# Train model
python train.py

# Run chatbot
python chatbot.py

# Test with samples
python chatbot.py test
```

---

## üí¨ **Example Conversation**

```
You: Hello

Bot: Hi there! How can I assist you today?
     üü¢ [greeting | 100.0%]

You: I have a fever

Bot: A fever usually indicates an infection. Stay hydrated and rest.
     If it's above 103¬∞F or lasts more than 3 days, see a doctor.
     üü¢ [fever | 100.0%]

You: My throat hurts

Bot: Sore throats are often caused by viral infections. 
     Gargle with warm salt water.
     üü¢ [sore_throat | 100.0%]

You: I've been coughing

Bot: A persistent cough can have many causes. 
     Stay hydrated and avoid irritants.
     üü¢ [cough | 100.0%]

You: Thank you

Bot: You're welcome! Feel free to ask if you need more help.
     üü¢ [thanks | 100.0%]

You: Goodbye

Bot: Goodbye! Take care of your health! üëã
```

---

## üéØ **Supported Intents**

The chatbot recognizes **12 intent categories** with high accuracy:

| Category | Examples | Patterns | Precision | Recall | F1-Score |
|----------|----------|----------|-----------|--------|----------|
| **Greeting** | "Hello", "Hi", "Good morning" | 91 | 1.00 | 0.71 | 0.83 |
| **How Are You** | "How are you?", "How's it going?" | 30 | 1.00 | 0.75 | 0.86 |
| **Goodbye** | "Bye", "See you", "Take care" | 86 | 0.92 | 0.92 | 0.92 |
| **Thanks** | "Thank you", "Thanks", "Appreciate it" | 87 | 1.00 | 1.00 | 1.00 |
| **Fever** | "I have a fever", "High temperature" | 70 | 1.00 | 1.00 | 1.00 |
| **Cold** | "I have a cold", "Cold symptoms" | 70 | 1.00 | 1.00 | 1.00 |
| **Flu** | "I think I have the flu" | 70 | 1.00 | 1.00 | 1.00 |
| **Cough** | "I'm coughing", "Can't stop coughing" | 70 | 1.00 | 1.00 | 1.00 |
| **Sore Throat** | "My throat hurts", "Throat pain" | 70 | 1.00 | 1.00 | 1.00 |
| **Congestion** | "Stuffy nose", "Can't breathe" | 70 | 0.91 | 1.00 | 0.95 |
| **Shortness of Breath** | "Hard to breathe", "Breathless" | 70 | 0.85 | 1.00 | 0.92 |
| **Headache** | "I have a headache", "Head hurts" | 70 | 0.75 | 0.90 | 0.82 |

**Total**: 854 training patterns ‚Ä¢ **Overall Accuracy**: 94.57%

---

## üîß **Configuration**

Edit `config/config.py` to customize:

### **Model Architecture**
```python
MODEL_CONFIG = {
    'embedding_dim': 256,      # Word embedding size
    'hidden_dim': 512,         # LSTM hidden units
    'num_layers': 3,           # Number of LSTM layers
    'dropout': 0.7,            # Dropout rate
    'bidirectional': True,     # Use BiLSTM
    'attention': True          # Use attention mechanism
}
```

### **Training Parameters**
```python
TRAINING_CONFIG = {
    'num_epochs': 1000,               # Maximum epochs
    'batch_size': 16,                 # Batch size
    'learning_rate': 0.003,           # Learning rate
    'early_stopping_patience': 30,    # Early stopping patience
    'train_split': 0.7,               # 70% training
    'val_split': 0.15,                # 15% validation
    'test_split': 0.15                # 15% testing
}
```

---

## üìä **Training Results**

### **Training History**
![Training History](outputs/metrics/training_history.png)

- **Best Validation Accuracy**: 89.84% (Epoch 30)
- **Final Test Accuracy**: 94.57%
- **Training stopped at**: Epoch 58 (early stopping)
- **Training samples**: 597 ‚Ä¢ **Validation**: 128 ‚Ä¢ **Test**: 129

### **Confusion Matrix**
![Confusion Matrix](outputs/metrics/confusion_matrix.png)

### **Per-Class Performance**
![Per-Class Metrics](outputs/metrics/per_class_metrics.png)

---

## üõ†Ô∏è **Technical Details**

### **Model Architecture**
- **Input**: Variable-length sequences (max 50 tokens)
- **Embedding**: 256-dimensional Word2Vec (trained on domain data)
- **Encoder**: 3-layer BiLSTM (512 hidden units per direction = 1024 total)
- **Attention**: Weighted sum over LSTM outputs for context-aware predictions
- **Classifier**: 2 fully-connected layers with ReLU activation + Dropout
- **Output**: 12-class softmax
- **Parameters**: 16,353,037 trainable parameters

### **Training Process**
1. **Data**: 854 patterns across 12 intent categories
2. **Vocabulary**: 265 unique tokens (stemmed)
3. **Word2Vec**: Skip-gram model, 256 dimensions, window=5, 20 epochs
4. **Optimization**: Adam optimizer (lr=0.003, weight_decay=1e-5)
5. **Regularization**: Dropout (0.7), Gradient clipping (max_norm=5.0)
6. **Learning Rate**: ReduceLROnPlateau scheduler (factor=0.5, patience=20)
7. **Early Stopping**: Patience=30 epochs (stops when validation loss plateaus)

### **Preprocessing Pipeline**
1. Text cleaning (remove special characters, normalize whitespace)
2. Tokenization (NLTK word_tokenize)
3. Lowercasing
4. Stemming (Porter Stemmer)
5. Vocabulary encoding (word ‚Üí index mapping)
6. Padding/Truncation to 50 tokens
7. Sequence length tracking (for packed sequences in LSTM)

---

## üìà **Performance Analysis**

### **Strengths**
- ‚úÖ **Perfect symptom detection**: Fever, cold, flu, cough, sore throat (100% precision & recall)
- ‚úÖ **Excellent conversational flow**: Thanks (100% F1), Goodbye (92% F1)
- ‚úÖ **Robust to variations**: Handles "I have fever", "I got a fever", "feeling feverish"
- ‚úÖ **Fast inference**: <100ms per query on CPU
- ‚úÖ **Well-balanced**: No overfitting (train 99.5% vs test 94.6%)

### **Known Limitations**
- ‚ö†Ô∏è Greeting intent has lower recall (71%) - some greetings classified as other intents
- ‚ö†Ô∏è "I'm feeling sick" without specific symptom may classify as flu (general symptoms)
- ‚ö†Ô∏è Questions like "How long does the flu last?" or "Is this serious?" not explicitly supported (were removed to improve core symptom detection)

### **Future Enhancements**
- üîÑ Re-add duration/severity intents with better data separation
- üîÑ Multi-label classification for multiple symptoms ("fever and cough")
- üîÑ Add more symptom categories (nausea, dizziness, fatigue, stomach ache)
- üîÑ Implement conversation context/memory
- üîÑ Deploy REST API (Flask/FastAPI)
- üîÑ Add confidence threshold tuning
- üîÑ Support for multilingual queries

---

## üêõ **Troubleshooting**

### **Model Not Found Error**
```bash
# Solution: Train the model first
python run.py train
```

### **NLTK Data Missing**
```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('wordnet'); nltk.download('stopwords'); nltk.download('punkt_tab'); nltk.download('omw-1.4')"
```

### **Import Errors**
```bash
# Reinstall dependencies
pip install -r requirements.txt --upgrade
```

### **Incorrect Predictions**
- Ensure you're using `intents_working.json` as training data
- Check that `chatbot.py` loads model config from checkpoint
- Verify sequence lengths are passed to the model during inference

---

## üìö **Technical Stack**

| Component | Technology | Version |
|-----------|-----------|---------|
| **Deep Learning** | PyTorch | 2.0+ |
| **NLP** | NLTK | 3.8+ |
| **Embeddings** | Gensim (Word2Vec) | 4.3+ |
| **Data Processing** | NumPy, Pandas | Latest |
| **Visualization** | Matplotlib, Seaborn | Latest |
| **Metrics** | Scikit-learn | 1.3+ |
| **API (Planned)** | Flask | 2.3+ |
| **Logging** | Colorlog | 6.7+ |

---

## üéì **Learning Outcomes**

This project demonstrates:
- ‚úÖ **Deep Learning**: BiLSTM architecture with attention mechanism
- ‚úÖ **NLP Techniques**: Tokenization, stemming, word embeddings
- ‚úÖ **Model Training**: Proper train/val/test splits, early stopping, hyperparameter tuning
- ‚úÖ **Evaluation**: Comprehensive metrics, confusion matrices, performance analysis
- ‚úÖ **Production Code**: Modular design, configuration management, error handling
- ‚úÖ **Debugging Skills**: Identifying and fixing vocabulary mismatch, inference issues

---

## ü§ù **Contributing**

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## üìÑ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üë§ **Author**

**Your Name**
- GitHub: [@yourusername](https://github.com/yourusername)
- LinkedIn: [Your Profile](https://linkedin.com/in/yourprofile)
- Email: your.email@example.com

---

## üôè **Acknowledgments**

- **NLTK** for natural language processing tools
- **PyTorch** for the deep learning framework
- **Gensim** for Word2Vec embeddings
- Healthcare domain knowledge from medical resources

---

## ‚≠ê **Star This Repository**

If you found this project helpful, please consider giving it a ‚≠ê on GitHub!

---

<p align="center">
  <strong>Made with ‚ù§Ô∏è for Healthcare NLP</strong>
</p>

<p align="center">
  <sub>A demonstration of BiLSTM + Attention for intent classification in healthcare domain</sub>
</p># üè• Healthcare Chatbot - NLP Project

An intelligent healthcare chatbot using **BiLSTM + Attention mechanism** for intent classification and symptom detection. Built with PyTorch, this chatbot can understand natural language queries about common health symptoms and provide appropriate responses.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## üìä **Performance Metrics**

- **Test Accuracy**: 94.57%
- **F1 Score (Weighted)**: 94.48%
- **F1 Score (Macro)**: 94.17%
- **Model Size**: 16.3M parameters
- **Training Time**: ~15 minutes (CPU)
- **Inference Speed**: <100ms per query

---

## ‚ú® **Key Features**

- üß† **Advanced Architecture**: BiLSTM with Attention mechanism
- üéØ **High Accuracy**: 94%+ accuracy on test set
- üí¨ **Natural Language**: Understands variations like "I have a fever", "I got fever", "my temperature is high"
- üîç **12 Intent Categories**: Greetings, farewells, thanks, and 8 health symptoms
- üìà **Word2Vec Embeddings**: 256-dimensional pre-trained embeddings
- üé® **Interactive CLI**: Real-time chat interface with confidence scores
- üìä **Comprehensive Metrics**: Confusion matrices, training history, per-class performance

---

## üèóÔ∏è **Architecture**

```
User Input: "I have a fever"
        ‚Üì
[Tokenization & Stemming]
        ‚Üì
[Word2Vec Embeddings] (256-dim)
        ‚Üì
[BiLSTM] (3 layers, 512 hidden units, bidirectional)
        ‚Üì
[Attention Layer] (focuses on important words)
        ‚Üì
[Fully Connected Layers]
        ‚Üì
[Softmax] ‚Üí Intent Classification
        ‚Üì
Output: "fever" (100% confidence)
```

### **Model Components:**
- **Embedding Layer**: 256-dimensional Word2Vec embeddings
- **BiLSTM**: 3 layers with 512 hidden units (bidirectional)
- **Attention Mechanism**: Weighted sum of LSTM outputs
- **Dropout**: 0.7 for regularization
- **Output**: 12 intent classes

---

## üìÅ **Project Structure**

```
healthcare-chatbot/
‚îú‚îÄ‚îÄ README.md                   # Project documentation
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ .gitignore                 # Git ignore rules
‚îú‚îÄ‚îÄ train.py                   # Model training script
‚îú‚îÄ‚îÄ chatbot.py                 # Interactive chatbot interface
‚îú‚îÄ‚îÄ run.py                     # Unified entry point
‚îÇ
‚îú‚îÄ‚îÄ api/                       # API module (future implementation)
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py              # Configuration settings
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ intents_working.json   # Training data (854 patterns)
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ neural_net.py          # BiLSTM + Attention model
‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py      # Data preprocessing pipeline
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py          # Word2Vec training
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ nltk_utils.py          # Text preprocessing utilities
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py          # Model evaluation & metrics
‚îÇ   ‚îî‚îÄ‚îÄ logger.py              # Logging utilities
‚îÇ
‚îî‚îÄ‚îÄ outputs/
    ‚îú‚îÄ‚îÄ models/
    ‚îÇ   ‚îú‚îÄ‚îÄ best_model.pth           # Trained model (94.57% accuracy)
    ‚îÇ   ‚îú‚îÄ‚îÄ training_data.pkl        # Preprocessed data
    ‚îÇ   ‚îî‚îÄ‚îÄ embeddings.pkl           # Word2Vec embeddings
    ‚îú‚îÄ‚îÄ logs/                        # Training logs
    ‚îî‚îÄ‚îÄ metrics/
        ‚îú‚îÄ‚îÄ confusion_matrix.png            # Confusion matrix
        ‚îú‚îÄ‚îÄ training_history.png            # Training curves
        ‚îú‚îÄ‚îÄ per_class_metrics.png           # Per-intent metrics
        ‚îî‚îÄ‚îÄ classification_report.txt       # Detailed metrics
```

---

## üöÄ **Quick Start**

### **Prerequisites**
- Python 3.8 or higher
- pip (Python package manager)
- 2GB RAM minimum
- ~500MB disk space

### **Installation**

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/healthcare-chatbot.git
   cd healthcare-chatbot
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   
   # Activate (Linux/Mac)
   source venv/bin/activate
   
   # Activate (Windows)
   venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

4. **Download NLTK data**
   ```bash
   python -c "import nltk; nltk.download('punkt'); nltk.download('wordnet'); nltk.download('stopwords'); nltk.download('punkt_tab'); nltk.download('omw-1.4')"
   ```

---

## üíª **Usage**

### **Option 1: Using run.py (Recommended)**

```bash
# Train the model
python run.py train

# Run interactive chatbot
python run.py chat

# Quick test
python run.py test
```

### **Option 2: Direct Scripts**

```bash
# Train model
python train.py

# Run chatbot
python chatbot.py

# Test with samples
python chatbot.py test
```

---

## üí¨ **Example Conversation**

```
You: Hello

Bot: Hi there! How can I assist you today?
     üü¢ [greeting | 100.0%]

You: I have a fever

Bot: A fever usually indicates an infection. Stay hydrated and rest.
     If it's above 103¬∞F or lasts more than 3 days, see a doctor.
     üü¢ [fever | 100.0%]

You: My throat hurts

Bot: Sore throats are often caused by viral infections. 
     Gargle with warm salt water.
     üü¢ [sore_throat | 100.0%]

You: I've been coughing

Bot: A persistent cough can have many causes. 
     Stay hydrated and avoid irritants.
     üü¢ [cough | 100.0%]

You: Thank you

Bot: You're welcome! Feel free to ask if you need more help.
     üü¢ [thanks | 100.0%]

You: Goodbye

Bot: Goodbye! Take care of your health! üëã
```

---

## üéØ **Supported Intents**

The chatbot recognizes **12 intent categories** with high accuracy:

| Category | Examples | Patterns | Precision | Recall | F1-Score |
|----------|----------|----------|-----------|--------|----------|
| **Greeting** | "Hello", "Hi", "Good morning" | 91 | 1.00 | 0.71 | 0.83 |
| **How Are You** | "How are you?", "How's it going?" | 30 | 1.00 | 0.75 | 0.86 |
| **Goodbye** | "Bye", "See you", "Take care" | 86 | 0.92 | 0.92 | 0.92 |
| **Thanks** | "Thank you", "Thanks", "Appreciate it" | 87 | 1.00 | 1.00 | 1.00 |
| **Fever** | "I have a fever", "High temperature" | 70 | 1.00 | 1.00 | 1.00 |
| **Cold** | "I have a cold", "Cold symptoms" | 70 | 1.00 | 1.00 | 1.00 |
| **Flu** | "I think I have the flu" | 70 | 1.00 | 1.00 | 1.00 |
| **Cough** | "I'm coughing", "Can't stop coughing" | 70 | 1.00 | 1.00 | 1.00 |
| **Sore Throat** | "My throat hurts", "Throat pain" | 70 | 1.00 | 1.00 | 1.00 |
| **Congestion** | "Stuffy nose", "Can't breathe" | 70 | 0.91 | 1.00 | 0.95 |
| **Shortness of Breath** | "Hard to breathe", "Breathless" | 70 | 0.85 | 1.00 | 0.92 |
| **Headache** | "I have a headache", "Head hurts" | 70 | 0.75 | 0.90 | 0.82 |

**Total**: 854 training patterns ‚Ä¢ **Overall Accuracy**: 94.57%

---

## üîß **Configuration**

Edit `config/config.py` to customize:

### **Model Architecture**
```python
MODEL_CONFIG = {
    'embedding_dim': 256,      # Word embedding size
    'hidden_dim': 512,         # LSTM hidden units
    'num_layers': 3,           # Number of LSTM layers
    'dropout': 0.7,            # Dropout rate
    'bidirectional': True,     # Use BiLSTM
    'attention': True          # Use attention mechanism
}
```

### **Training Parameters**
```python
TRAINING_CONFIG = {
    'num_epochs': 1000,               # Maximum epochs
    'batch_size': 16,                 # Batch size
    'learning_rate': 0.003,           # Learning rate
    'early_stopping_patience': 30,    # Early stopping patience
    'train_split': 0.7,               # 70% training
    'val_split': 0.15,                # 15% validation
    'test_split': 0.15                # 15% testing
}
```

---

## üìä **Training Results**

### **Training History**
![Training History](outputs/metrics/training_history.png)

- **Best Validation Accuracy**: 89.84% (Epoch 30)
- **Final Test Accuracy**: 94.57%
- **Training stopped at**: Epoch 58 (early stopping)
- **Training samples**: 597 ‚Ä¢ **Validation**: 128 ‚Ä¢ **Test**: 129

### **Confusion Matrix**
![Confusion Matrix](outputs/metrics/confusion_matrix.png)

### **Per-Class Performance**
![Per-Class Metrics](outputs/metrics/per_class_metrics.png)

---

## üõ†Ô∏è **Technical Details**

### **Model Architecture**
- **Input**: Variable-length sequences (max 50 tokens)
- **Embedding**: 256-dimensional Word2Vec (trained on domain data)
- **Encoder**: 3-layer BiLSTM (512 hidden units per direction = 1024 total)
- **Attention**: Weighted sum over LSTM outputs for context-aware predictions
- **Classifier**: 2 fully-connected layers with ReLU activation + Dropout
- **Output**: 12-class softmax
- **Parameters**: 16,353,037 trainable parameters

### **Training Process**
1. **Data**: 854 patterns across 12 intent categories
2. **Vocabulary**: 265 unique tokens (stemmed)
3. **Word2Vec**: Skip-gram model, 256 dimensions, window=5, 20 epochs
4. **Optimization**: Adam optimizer (lr=0.003, weight_decay=1e-5)
5. **Regularization**: Dropout (0.7), Gradient clipping (max_norm=5.0)
6. **Learning Rate**: ReduceLROnPlateau scheduler (factor=0.5, patience=20)
7. **Early Stopping**: Patience=30 epochs (stops when validation loss plateaus)

### **Preprocessing Pipeline**
1. Text cleaning (remove special characters, normalize whitespace)
2. Tokenization (NLTK word_tokenize)
3. Lowercasing
4. Stemming (Porter Stemmer)
5. Vocabulary encoding (word ‚Üí index mapping)
6. Padding/Truncation to 50 tokens
7. Sequence length tracking (for packed sequences in LSTM)

---

## üìà **Performance Analysis**

### **Strengths**
- ‚úÖ **Perfect symptom detection**: Fever, cold, flu, cough, sore throat (100% precision & recall)
- ‚úÖ **Excellent conversational flow**: Thanks (100% F1), Goodbye (92% F1)
- ‚úÖ **Robust to variations**: Handles "I have fever", "I got a fever", "feeling feverish"
- ‚úÖ **Fast inference**: <100ms per query on CPU
- ‚úÖ **Well-balanced**: No overfitting (train 99.5% vs test 94.6%)

### **Known Limitations**
- ‚ö†Ô∏è Greeting intent has lower recall (71%) - some greetings classified as other intents
- ‚ö†Ô∏è "I'm feeling sick" without specific symptom may classify as flu (general symptoms)
- ‚ö†Ô∏è Questions like "How long does the flu last?" or "Is this serious?" not explicitly supported (were removed to improve core symptom detection)

### **Future Enhancements**
- üîÑ Re-add duration/severity intents with better data separation
- üîÑ Multi-label classification for multiple symptoms ("fever and cough")
- üîÑ Add more symptom categories (nausea, dizziness, fatigue, stomach ache)
- üîÑ Implement conversation context/memory
- üîÑ Deploy REST API (Flask/FastAPI)
- üîÑ Add confidence threshold tuning
- üîÑ Support for multilingual queries

---

## üêõ **Troubleshooting**

### **Model Not Found Error**
```bash
# Solution: Train the model first
python run.py train
```

### **NLTK Data Missing**
```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('wordnet'); nltk.download('stopwords'); nltk.download('punkt_tab'); nltk.download('omw-1.4')"
```

### **Import Errors**
```bash
# Reinstall dependencies
pip install -r requirements.txt --upgrade
```

### **Incorrect Predictions**
- Ensure you're using `intents_working.json` as training data
- Check that `chatbot.py` loads model config from checkpoint
- Verify sequence lengths are passed to the model during inference

---

## üìö **Technical Stack**

| Component | Technology | Version |
|-----------|-----------|---------|
| **Deep Learning** | PyTorch | 2.0+ |
| **NLP** | NLTK | 3.8+ |
| **Embeddings** | Gensim (Word2Vec) | 4.3+ |
| **Data Processing** | NumPy, Pandas | Latest |
| **Visualization** | Matplotlib, Seaborn | Latest |
| **Metrics** | Scikit-learn | 1.3+ |
| **API (Planned)** | Flask | 2.3+ |
| **Logging** | Colorlog | 6.7+ |

---

## üéì **Learning Outcomes**

This project demonstrates:
- ‚úÖ **Deep Learning**: BiLSTM architecture with attention mechanism
- ‚úÖ **NLP Techniques**: Tokenization, stemming, word embeddings
- ‚úÖ **Model Training**: Proper train/val/test splits, early stopping, hyperparameter tuning
- ‚úÖ **Evaluation**: Comprehensive metrics, confusion matrices, performance analysis
- ‚úÖ **Production Code**: Modular design, configuration management, error handling
- ‚úÖ **Debugging Skills**: Identifying and fixing vocabulary mismatch, inference issues

---

## ü§ù **Contributing**

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## üë§ **Author**

**Your Name**
- GitHub: [@Jinam-Shah](https://github.com/Jinam-Shah)

---
